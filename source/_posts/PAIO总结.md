---
title: PAIO总结
date: 2024-03-14 10:52:43
tags:
typora-root-url: ..
categories:
    - 论文阅读
---

# PAIO: General, Portable I/O Optimizations With Minor Application Modifications

论文原地址https://www.usenix.org/conference/fast22/presentation/macedo

## 摘要

PAIO是一个框架，为不同的应用程序实现**可移植**的I/O策略和**优化**，开发人员只需要对**原始的代码库**进行**少量修改**。主要思路是：如果我们能够在请求流经I/O堆栈的不同层时拦截和区分请求，我们就可以在不显著更改层本身的情况下执行复杂的存储策略。PAIO用到了软件定义存储的思想，构建了数据平面stages(mediate和优化跨层的I/O请求)和控制平面(根据不同的存储策略对各个步骤进行协调和微调)。用两个用例展示了PAIO的性能和适用性。

**第一种**方法将基于行业标准lsm的键值存储的第99百分位延迟提高了4倍。**第二个**是确保共享存储环境下动态的每个应用程序带宽保证

## Introduction

以数据为中心的系统已经逐渐成为I/O堆栈的一部分。通常使用存储优化( I/O scheduling, differentiation, and caching)来提高这种系统的性能。但这些优化方式和系统实现紧密耦合，并且由于缺乏全局上下文而可能相互干扰。例如，区分前台和后台I/O以减少尾部延迟等优化方法被广泛应用，然而现在在KVS中实现的方式需要对系统有深刻的理解，并且可移植性很低。类似地，部署在共享基础设施上的应用程序的优化可能由于彼此不了解而发生冲突。

> 基于基础架构的存储优化存在互相干扰、可移植性差、应用程序冲突的问题

本文认为存在一种更好的方式来实现存储优化。PAIO是一种用户级框架，通过采用软件定义存储(SDS)社区的思想，可以构建可移植且普遍适用的存储优化。**关键思想**是通过拦截和处理应用程序执行的I/O，在应用程序之外实现优化，作为数据平步骤。然后，这些优化由逻辑上集中的管理器(控制平面)控制，该管理器具有防止它们之间相互干扰所必需的全局上下文。PAIO不需要对内核进行修改，同时可以达到修改内核存储优化方法的效果。

> 关键思想是在数据平面优化每个应用程序的IO，然后在控制平面获取全局状态。

PAIO的实现面临了很多的挑战。为了在应用程序外部执行复杂的I/O优化，PAIO需要在I/O堆栈中向下传播上下文，从高级api向下传播到以较小粒度执行I/O的较低层。它通过结合上下文传播的思想来实现这一点，使应用程序级的信息能够传播到数据平面步骤，只需进行少量的代码更改，而无需修改现有的api。

> 挑战1是如何把应用程序的信息传播到数据平面

PAIO要求设计新的抽象，允许在用户空间I/O层之间区分和协调I/O请求，同时增强了存储优化的可移植性和易部署性。PAIO主要有四个抽象。`enforcement object`是一个可编程组件，它将单个用户定义的策略(例如速率限制或调度)应用于传入的I/O请求。PAIO使用`context objects`来描述和区分请求，并通过`channels`连接I/O请求、`enforcement object`和`context objects`。为了确保独立存储优化之间的协调(例如，公平性，优先级)，具有全局可见性的控制平面通过使用`rules`对`enforcement object`进行微调

```
用户空间I/O层是什么东西，具体有哪些
```

<img src="/images/PAIO总结/image-20240315163546597.png" alt="image-20240315163546597" style="zoom:67%;" />

> PAIO主要有四个抽象：enforcement object、context objects、channels、rules

使用上述的新特性和抽象，系统设计人员可以开发定制SDS数据平面步骤。为了演示这一点，我们用下面两个用例验证PAIO。**第一**，在RocksDB中添加了一个步骤，然后演示如何通过编排前台和后台任务来防止延迟峰值。结果表明，与基线RocksDB相比，在不同的工作负载和测试场景(例如，不同的存储设备，有和没有I/O带宽限制)下，启用PAIO的RocksDB将第99百分位延迟提高了4，并且与SILK相比实现了相似的尾延迟性能。这就证明了I/O优化可以更简单、更易移植的实现。**第二**，我们将PAIO应用于TensorFlow，并展示了如何在ABCI超级计算机的真实共享存储场景下实现动态的每个应用程序带宽保证。结果显示使用了PAIO的TensorFlow实例带宽目标都被满足了。

```
Software-Defined Storage(SDS)思想主要有什么
```

> PAIO在两个场景下进行了验证

本文贡献如下：

- 一个用户级框架，用于构建可编程和动态适应的数据平面步骤
- 实现了两个目标：(1)减少LSM KVS中的延迟峰值;(2)在共享存储设置下实现每个应用的带宽保证
- 实验结果验证了该方法在综合和真实场景下的性能和适用性

## Motivation and Challenges

当前系统内I/O优化的问题

### 紧耦合的优化

**问题描述**：大多数I/O优化都是单一用途的，因为它们紧密集成在每个系统的核心中。实现这些优化需要对内核有了解，并熟悉内部代码。这就限制了它们的可维护性和跨系统的可移植性。例如，为了减少RocksDB的尾部延迟峰值，SILK提出了一个I/O调度器来控制前台和后台任务之间的干扰。在RocksDB中实现SILK的优化需要修改很多核心模块的代码。并且SILK也不容易实现在别的KVS(LevelDB,pebble)中。

**解决方案**：解耦优化。I/O优化应该从系统的内部逻辑中分离出来，并转移到专用层，从而在不同的场景中变得普遍适用和可移植。

**挑战**：刚性接口。解耦优化是有代价的，因为没有办法使用系统特定优化中存在的粒度和内部应用程序知识。具体来说，传统的I/O堆栈模型需要通过难以扩展的严格接口进行通信，从而丢弃了可用于对不同粒度级别的请求进行分类和区分的信息。例如，图1是一个由应用程序、KVS和POSIX兼容的文件系统组成的I/O堆栈。从KVS提交的POSIX操作来自不同的工作流，包括前台流(a)和后台流，比如flush(b)和compactions(c)。文件系统只能获取请求的大小和类型，所以无法推断该请求的起源。将SILK I/O调度器实现在文件系统和KVS之间移植性较高。然而，它将是无效的，因为它不能区分前台和后台操作。

![image-20240315232733807](/images/PAIO总结/image-20240315232733807.png)

```
flush和compactions操作是什么样的。前台流和后台流举例子
为什么将SILK部署在文件系统之上就会是无效的了
```

> 每一层之间的接口调用都是严格的，上下层之间的信息不互通，所以调度的能力有限

**解决方案**：信息传播。application级别的信息必须在各个层之间传播，以确保解耦优化能够提供与系统特定优化相同级别的控制和性能。

**挑战**：内核层。如果在内核中实现SILK(文件系统、块层)可以增加它适配的KVS个数，但是也有几个缺点。首先，为了将application的信息传播到每一个层，它需要破坏用户到内核层(即POSIX)和内核内部接口，从而降低可移植性和兼容性。并且内核开发更难。最后，这些优化在绕过内核的存储栈中是无效的。

```
POSIX是什么
```

**解决方案**：用户层实现。I/O优化应该只在用户层实现，可以跨不同系统和场景，并且需要简化信息在各层之间的传播

### partial visibility(局部网格可见)

**问题描述**：单独实现的优化会忽略来自其他系统对相同存储资源的竞争。在共享基础设施(云计算、HPC)中，这个问题会导致冲突、I/O竞争以及应用程序和存储后端的性能变化。

**解决方案**：全局控制。优化应该了解周围的环境并协调操作，以确保对I/O工作流和共享资源进行全面控制。

> 就两个问题。
>
> 第一个问题是如何解耦，增加可移植性，适用性。以及解耦之后信息如何传递
>
> 第二个问题是信息如何在不同的应用程序之间共享

## PAIO in a Nutshell

PAIO是一个框架，使系统设计人员能够构建定制的SDS数据平面步骤。在数据平面步骤中使用的PAIO服务于给定user-level层的workflows，支持对请求进行分类和区分，并根据用户定义的存储策略实施不同的存储机制。此类策略的示例可以简单到限制贪婪租户的速率以实现资源公平，也可以复杂到协调具有不同优先级的工作流以确保持续的尾部延迟。PAIO的设计基于五个核心原则。

#### 普遍适用性

为了确保不同I/O层之间的适用性，PAIO的步骤从内部系统逻辑中分离出来。

#### 可编程构件

PAIO遵循解耦设计，将I/O机制与管理I/O的策略分开，并提供抽象，用于构建新的存储优化以应用于请求。

#### 细粒度的I/O控制

PAIO对不同粒度级别的I/O请求进行分类、区分和强制执行。支持在I/O堆栈上应用一组广泛的策略。

#### 步骤协调

为了确保步骤之间能够协调地获取资源，PAIO公开了一个控制接口，使控制平面能够动态地使每个步骤适应新的策略和工作负载变化

#### 低修改性

在I/O层上使用PAIO只需要很少的修改

### PAIO中的抽象

#### Enforcement object

Enforcement object是一种自包含的、单一用途的机制，它对传入的I/O请求应用自定义I/O逻辑。这种机制的例子包括：性能控制和资源管理(令牌桶和缓存)，数据转换(压缩和加密)，数据管理(数据预取、分层)。该抽象为系统设计人员提供了开发新机制(专门用于特定存储策略)的灵活性和可扩展性。

#### Channel

Channel是请求流通过的抽象。每一个channel有一个或者多个Enforcement object(对同一组请求应用不同的机制)

以及将请求映射到要enforced的相应Enforcement object的differentiation rule 

#### Context object

Context object包括描述请求特征的原信息。它包括一组元素(分类器)l例如流ID(例如thread-ID)，请求类型(例如read, open, put, get)，请求大小和请求context.请求context用于描述请求的附加信息，比如确定其起源、背景等。对于每一个请求，PAIO会生成相关的Context object用于在各自的I/O机制上对请求进行分类、区分和强制执行

#### Rule

在PAIO中，一条rule表示控制数据平面步骤状态的操作。rules由控制平面提交，分为三种类型：housekeeping rules管理内部步骤组织，differentiation rules分类和区分I/O请求，enforcement rules 根据工作负载变化调整enforcement object。

###  High-level Architecture

图二展示了PAIO的高层架构。它遵循一种解耦设计，将在外部控制平面实现的策略与在数据平面阶段实现的执行策略的机制分离开来。PAIO的目标是用户级的I/O层。步骤嵌入在层中，拦截所有的I/O请求然后强制执行用户定义的规则。为了达到这个目标，PAIO由四个主要部分组成。

![image-20240317195418962](/images/PAIO总结/image-20240317195418962.png)

#### Stage interface

应用程序通过stage接口进入stage，该接口在提交到下一个I/O层(文件系统)之前将所有请求路由到PAIO。对每一个请求，都会生成一个具有相应I/O分类器的Context object。

#### Differentiation moudle

区分模块根据请求的Context object对请求进行分类和区分。为了确保用细粒度来区分请求，我们使仅对层本身可访问的应用程序级信息能够传播到PAIO，从而扩大了可以执行的策略集。

#### Enforcement module

该模块负责在请求之间执行真正的I/O策略。它由channel和enforcement object 组成。对于每个请求，模块选择应该处理它的channel和enforcement object 。执行后，请求返回到原始数据路径并提交到下一个I/O层。(文件系统)

#### Control interface

PAIo提供了Control interface，允许控制平面(1)通过创建channels、enforcement objects和differentiation rules,来编排stage的生命周期，(2)通过持续监控和微调stage，确保所有政策得到满足。控制平面提供全局可视化，全面地控制所有的stages。暴露此接口允许由现有控制平面管理stages。

### A Day in the Life of a Request

PAIO如何服务一个工作流的。考虑图三所示的I/O堆栈，它由一个应用程序、RocksDB、一个PAIO阶段和一个posix兼容的文件系统组成。并且包含以下规则：限制RocksDB的flush操作速率为X MiB/s。RocksDB的背景流生成flush和compactions任务，在提交给文件系统之前会被转换成多种POSIX请求。flush被转换成write，conmpactions被转换成read和write。

![image-20240317202819785](/images/PAIO总结/image-20240317202819785.png)

开始阶段，RocksDB初始化PAIO stage，连接到已经部署的控制平面。控制平面提交 housekeeping rules，以创建一个channel和一个enforcement object，对X MiB的请求进行速率限制(白1)。它还提交区分规则(白2)，以确定stage应该处理哪些请求(基于flush的write)。

在执行阶段，RocksDB传播创建了给定操作的context(黑0)，并将所有写操作重定向到PAIO(黑1)。通过上一步可以确保旨在PAIO上强制执行写操作，通过使用 黑0 可以将带flush标记的写操作与其他可以由压缩作业触发的写操作区分开来。接下来stage选择要使用的channel，将请求入队，然后选择服务请求的enforcement object(将请求限制在XMiB/s)。执行请求之后，原写操作提交给文件系统。

控制平面会持续监事和微调数据平面stage。它定期从stage收集为该请求提供服务的吞吐量。根据该测量值，控制平面调整enforcement object来保证flush操作流的速度是X MiB/s，使用新的配置生成enforcement rules。

## I/O Differentiation

PAIO的区分模块提供了在不同粒度级别(即每个工作流、请求类型和请求上下文)对请求进行分类和区分的方法。通过三个步骤区分请求

#### Startup Time

开始的时候，用户定义如何区分请求以及谁应该处理每个请求。首先，它通过指定应该使用哪些I/O分类器来区分请求来定义区分的粒度。例如，为了区分每个workflow，PAIO只考虑Context’s workflow id分类器；而为了根据上下文和类型区分请求，它同时使用*request context*和*request type*分类器。























